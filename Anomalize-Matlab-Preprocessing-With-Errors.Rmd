---
title: "R Notebook"
output: html_notebook
---

```{r}
library(aws.s3)
save_object("Flight 652/1/652200101092009.mat", file="652200101092009.mat", bucket = "iia-vault-telemetry-practice-unzipped")
```

```{r}

# this is the "middle file" on the wiki page https://wiki.iiaweb.com/index.php?title=VAULT/RawData/DASHLink#Format
filename <- "652200101092009.mat"

library(tidyverse)
library(R.matlab)
library(jsonlite) # to save df as json

# when we get around to data exploration
library(ggcorrplot)
library(trelliscopejs)

data <- readMat(filename)
head(data)
```

```{r}
# I just highlighted the wiki table right off the screen and pasted it into TextEdit
catalog <- read_tsv("catalog.txt")

# look at it
head(catalog)
```

```{r}
# snake_case the column names
names(catalog) <- c("field_number","field_name", "field_description",
                    "units", "field_data_type", "field_sampling_rate",
                    "number_rows_first_file", "typical_value", 
                    "number_rows_middle_file", "plot")
View(catalog)
max(catalog$field_sampling_rate)
# [1] 124
min(catalog$field_sampling_rate)
# [1] 0.25
max(catalog$number_rows_middle_file)
# [1] 134592
min(catalog$number_rows_middle_file)
# [1] 363

sampling_ratio <- 124/0.25
row_ratio <- 134592/363

sampling_ratio
# 496
row_ratio
# 370.7769

assertthat::are_equal(sampling_ratio, row_ratio )
```
```{r}
table(catalog$number_rows_middle_file)

# 3.63   2103   8412  16824  33648  67296 134592 
# 1     23     87     18     49      4      4 

# remove 3.63 outlier

# what is actual value?

data$PTRM
# , , 1
# 
# [,1]                 
# data        Numeric,8412         
# Rate        1                    
# Units       "DEG"                
# Description "PITCH TRIM POSITION"
# Alpha       "PTRM"               


row_ratio_2 <- 134592/2104
row_ratio_2
# [1] 63.96958
unique(catalog$field_sampling_rate)
# [1]   0.25  16.00   4.00   1.00   8.00   2.00 124.00

# Actual value is 8412
# Replace the cell
# syntax: df[df$serial.id==5, "gender"] <- 1

# catalog[catalog$number_rows_middle_file == 3.63, "number_rows_middle_file"] <- 8412

# verify
View(catalog)

# fixed
catalog[catalog$field_name == "PTRM",]
# A tibble: 1 x 9
# field_number field_name field_description  units field_data_type field_sampling_r… number_rows_first… typical_value number_rows_middl…
# <dbl> <chr>      <chr>              <chr> <chr>                       <dbl>              <dbl>         <dbl>              <dbl>
# 147 PTRM       PITCH TRIM POSITI… DEG   FLOAT                           1                124         0.721               8412

# Get the actual values vector from a variable
my_lon <- unlist(data$LONP[1][1])
my_lat <- unlist(data$LATP[1][1])

position_df <- tibble(my_lon, my_lat)

str(position_df)
# tibble [8,412 × 2] (S3: tbl_df/tbl/data.frame)
# $ my_lon: num [1:8412] -93.2 -93.2 -93.2 -93.2 -93.2 ...
# $ my_lat: num [1:8412] 44.9 44.9 44.9 44.9 44.9 ...

# works but where on world is it?
#ggplot(data = position_df, aes(x = my_lon, y = my_lat, group = 1), fill = NA, color = "red") +
 # geom_point()
```






```{r}
# copy our catalog
catalog2 <- catalog

# repair mistakes

# Fix field name
catalog2[135, "field_name" ] <- "LONP"
catalog2[135, "field_description" ] <- "LONGITUDE POSITION LSP"
catalog2[135, "units" ] <- "DEG"
catalog2[135, "field_data_type" ] <- "FLOAT"
catalog2[135, "field_sampling_rate" ] <- 1
catalog2[135, "number_rows_first_file" ] <- 124.000
catalog2[135, "typical_value" ] <- -93.2000

# check it
catalog2[135,]

# Fix outlier number of rows for PTRIM
catalog2[147, "number_rows_middle_file"] <- 8412

# check it
catalog2[147,]

# save the cleansed catalog
save(catalog2, file = "data/catalog2.Rda")

# rename our data something more descriptive and save it
dashlink_data <- data
save(dashlink_data, file = "data/dashlink_data.Rda")

# NOW LET'S LOOK AT MAX MIN AND TIME AGAIN

table(catalog2$field_sampling_rate)
# 0.25    1    2    4    8   16 
#   23   88   18   49    4    4 

table(catalog2$number_rows_middle_file)
# 2103   8412  16824  33648  67296 134592 
#   23     88     18     49      4      4 

(min_sample_rate <- min(catalog2$field_sampling_rate, na.rm=TRUE))
# [1] 0.25
(max_sample_rate <- max(catalog2$field_sampling_rate, na.rm=TRUE))
# [1] 16
(min_rows <- min(catalog2$number_rows_middle_file, na.rm=TRUE))
# [1] 2103
(max_rows <- max(catalog2$number_rows_middle_file, na.rm=TRUE))
# [1] 134592
(sample_ratio <- max_sample_rate / min_sample_rate)
# [1] 64
(row_ratio <- max_rows / min_rows)
# [1] 64
assertthat::are_equal(sample_ratio, row_ratio)
# [1] TRUE
assertthat::are_equal(max_rows, 64 * min_rows)
# TRUE

# Figuring out how to use "rep()" ("repeat") to normalize the lengths
# for each vector, We need to repeat each element the right nuber of times to adjust for slower sample rates 
oldvec <- c("A", "B", "C", "D", "E", "F", "G", "H")
oldvec
# [1] "A" "B" "C" "D" "E" "F" "G" "H"

newvec <- rep(oldvec, each = 3)
newvec
# [1] "A" "A" "A" "B" "B" "B" "C" "C" "C" "D" "D" "D" "E" "E" "E" "F" "F" "F" "G" "G" "G" "H" "H" "H"

# THEREFORE, for each vector,
# the "each" parameter needs to be:
# max_rows / length(vec)

# Need to preserve the name

# not named
names(my_lon)
# NULL

# not named
names(data$LONP[1][1])
# NULL

# not named
names(data$LONP[1])
# NULL

# not named
names(data$LONP)
# NULL

# named !!
names(data)
# SWEET !!

# extract a simple vector of names
names_index <- names(data)

# cycle through like this
x <- 1:length(data)
current_index <- names_index[x]

# extract a simple vector
#current_column <- unlist(data[[current_index]][1][1])

# make sure it is a vector not a list
# WOO-HOO !!

#str(current_column)
# num [1:2103] 584 584 584 584 584 584 584 584 584 584 ...
```

```{r}
# vector of integers from 1 to max_rows to construct a tibble from
drop_me_later <- 1:max_rows

# create a tibble
# we will cbind all 186 normalized vectors to it as columns
normalized_df <- tibble(drop_me = drop_me_later)

# 186 loops
for(i in 1:length(data)) {
  # the current column name
  current_index <- names_index[i]
  
  # the current tibble column
  current_column <- unlist(data[[current_index]][1][1])
  
  # the current column length
  current_length <- length(current_column)
  
  # the current multiplier
  current_multiplier <- max_rows / current_length
  
  # the normalized current column
  current_normalized_column <- rep(current_column, each = current_multiplier)

  # bind the column  
  normalized_df <- cbind(normalized_df, current_normalized_column  )

  # fix the name of the new column (it wnats to name it after the variable)
  names(normalized_df)[names(normalized_df) == "current_normalized_column"] <- current_index
}

# check the names and structure  
str(normalized_df)
```

# Create a Filename Programatically and Save Output
```{r}
file_prefix <- gsub(".mat", "", filename)
paste(file_prefix,".Rda", sep="")
```

# Addendum
```{r}
# add US map

library(ggmap)
library(maps)
library(mapdata)

usa <- map_data("usa")

# plot data in red, CONUS in blue
# I saved this as PNG from the Viewer panel

ggplot() +
  geom_point(data = position_df, aes(x = my_lon, y = my_lat, group = 1), fill = NA, color = "red") +

  geom_polygon(data = usa, aes(x=long, y = lat, group = group), fill = NA, color = "blue") + 
  coord_fixed(1.3)
```