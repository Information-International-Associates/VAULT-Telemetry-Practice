{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "MphZayxBk8o4",
    "outputId": "32e6df4a-0966-4d7b-a545-2cd0d9fe7b00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (1.14.37)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.37 in /opt/conda/lib/python3.7/site-packages (from boto3) (1.17.37)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.37->boto3) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.37->boto3) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.37->boto3) (1.25.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.37->boto3) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "def s3_bucket_object_keys(bucket_name= 'iia-vault-telemetry-practice-unzipped'):\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    key_list=[]\n",
    "    for key in bucket.objects.all():\n",
    "        key_list.append(key)\n",
    "    return(key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "def load_mat_file(s3_key, bucketname= 'iia-vault-telemetry-practice-unzipped'):\n",
    "    s3 = boto3.resource('s3')\n",
    "    obj = s3.Object(bucketname, s3_key)\n",
    "    inMATFile = obj.get()['Body'].read()\n",
    "    raw_mat = io.loadmat(BytesIO(inMATFile))\n",
    "    return(raw_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to run the funtion  0:00:18.019696\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "key_list = s3_bucket_object_keys()\n",
    "end = datetime.datetime.now()\n",
    "print(\"Time Taken to run the funtion \",str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "m0Ji9b7hkvMW",
    "outputId": "31ca33d4-5a96-48b0-b395-d88063e47929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to run the funtion  0:00:00.000235\n"
     ]
    }
   ],
   "source": [
    "from scipy import io\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.lib import recfunctions\n",
    "import datetime\n",
    "import numpy.lib.recfunctions as recfn\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# # Open flight .mat file as a python dictionary\n",
    "# def open_mat_file(file_name):\n",
    "#     #start = datetime.datetime.now()\n",
    "#     inMATFile = file_name\n",
    "#     raw_data = io.loadmat(inMATFile)\n",
    "#     #end = datetime.datetime.now()\n",
    "#     #print(\"Time Taken to run the open_mat_file \",str(end-start))\n",
    "#     return raw_data\n",
    "\n",
    "\n",
    "# Extract the names of the features (i.e. the keys in the raw python dictionary)\n",
    "# starting point: 189 features\n",
    "# Delete 3 specific keys since they are metadata and not associated with the blackbox data\n",
    "# intermediate total: 186\n",
    "# Delete all features that have resolution < 1Hz since these are  static and non-relevant\n",
    "# Final total: 163\n",
    "\n",
    "def extract_features(raw_data):\n",
    "    \n",
    "    features = raw_data.keys()\n",
    "    features_25 = []\n",
    "    features_1 = []\n",
    "    data_def=[]\n",
    "    number_of_features =  len(features) \n",
    "    #print number_of_features\n",
    "#     del features[137]\n",
    "#     del features[160]\n",
    "#     del features[181]\n",
    "    for key in features:\n",
    "        if key == '__header__' or key == '__version__' or key == '__globals__':\n",
    "            continue\n",
    "        data =  raw_data[key]['data'][0][0].T\n",
    "        rate =  raw_data[key]['Rate'][0][0][0][0]\n",
    "        try:\n",
    "            units= raw_data[key]['Units'][0][0][0]\n",
    "        except:\n",
    "            units= None\n",
    "        dtype = raw_data[key]['data'][0][0][0][0].dtype\n",
    "        desc = raw_data[key][0][0][3][0]\n",
    "        data_def.append([key, len(data),rate, units, dtype, desc, data])\n",
    "#         features_scrubbed.append(key)\n",
    "        if rate == 0.25: # sample rate < 1Hz\n",
    "            #interpolate_to_1hz(data)\n",
    "            features_25.append(key)\n",
    "        else: # sample rate > 1Hz\n",
    "            features_1.append(key)\n",
    "#     #print len(features_scrubbed)\n",
    "    return features_25, features_1, data_def\n",
    "\n",
    "# Create recarray with feature vectors. Normalize all feature data vectors to fit the 1Hz resolution\n",
    "def feature_vector_array(raw_data, features_25, features_1,file_name):\n",
    "    arr_dict = {}\n",
    "    # Setup of final array\n",
    "    # arr = np.zeros((len(raw_data['SAT']['data'][0][0])),dtype=[('timestamp', np.str_, 20)]) #'datetime64[us]'\n",
    "    ff = features_1+features_25\n",
    "    d_length = len(ff)\n",
    "    t_length = len(raw_data['SAT']['data'][0][0])\n",
    "    arrs_1d = [0]\n",
    "    \n",
    "    # selecting the base timestamp (first record in file) and filling first column of csv with timestamp data based on it\n",
    "    year       = raw_data['DATE_YEAR']['data'][0][0][0,0]\n",
    "    month      = raw_data['DATE_MONTH']['data'][0][0][0,0]\n",
    "    day        = raw_data['DATE_DAY']['data'][0][0][0,0]\n",
    "    hour       = raw_data['GMT_HOUR']['data'][0][0][0,0]\n",
    "    minute     = raw_data['GMT_MINUTE']['data'][0][0][0,0]\n",
    "    sec        = raw_data['GMT_SEC']['data'][0][0][0,0]\n",
    "\n",
    "    # 687200403251247.mat\n",
    "    if month <1 or month > 12:\n",
    "      year = int(file_name[3:7])\n",
    "      month = int(file_name[7:9])\n",
    "      day = int(file_name[9:11])\n",
    "      hour = int(file_name[11:13])\n",
    "      minute = int(file_name[13:15])\n",
    "      sec = 0\n",
    "\n",
    "    base = datetime.datetime(year, month, day, hour, minute, sec)\n",
    "    date_list = [base + datetime.timedelta(seconds=x) for x in range(0, t_length)]\n",
    "    dates = np.array(date_list)\n",
    "#     flghtnum= np.repeat(file_name, len(dates))\n",
    "    # arr['timestamp'] = dates\n",
    "    feature_dict['timestamp'] = (dates.T).tolist()\n",
    "    \n",
    "    # Filling all feature vector columns in the recarray\n",
    "    for key in features_1:\n",
    "        data =  raw_data[key]['data'][0][0]\n",
    "        rate =  raw_data[key]['Rate'][0][0][0][0]\n",
    "        dtype = raw_data[key]['data'][0][0].dtype\n",
    "        # Add column to the recarray with proper dtype\n",
    "        # arr = recfn.rec_append_fields(arr, key, arrs_1d, dtype)\n",
    "        # Normalize vector to 1Hz by subsampling original vector\n",
    "        norm_v = data[0:data.size:rate]\n",
    "        # Add normalized feature data vector to added column\n",
    "        # arr[key] = norm_v.T\n",
    "        feature_dict[key] = (norm_v.T).tolist()[0]\n",
    "    size_1hz = len(norm_v)\n",
    "    for key in features_25:\n",
    "        data =  raw_data[key]['data'][0][0]\n",
    "        rate =  raw_data[key]['Rate'][0][0][0][0]\n",
    "        dtype = raw_data[key]['data'][0][0].dtype\n",
    "        # Add column to the recarray with proper dtype\n",
    "        # arr = recfn.rec_append_fields(arr, key, arrs_1d, dtype)\n",
    "        # Normalize vector to 1Hz by subsampling original vector\n",
    "        norm_v = np.resize(data,(size_1hz,1))\n",
    "        # Add normalized feature data vector to added column\n",
    "        # arr[key] = norm_v.T\n",
    "        feature_dict[key] = (norm_v.T).tolist()[0]\n",
    "        # print((norm_v.T).tolist()[0])\n",
    "    return\n",
    "\n",
    "def feature_dictionary(feature_dict,raw_data,features_25, features_1,file_name):\n",
    "\n",
    "    # Setup of final array\n",
    "    # arr = np.zeros((len(raw_data['SAT']['data'][0][0])),dtype=[('timestamp', np.str_, 20)]) #'datetime64[us]'\n",
    "    ff = features_1+features_25\n",
    "    d_length = len(ff)\n",
    "    t_length = len(raw_data['SAT']['data'][0][0])\n",
    "    arrs_1d = [0]\n",
    "    \n",
    "    # selecting the base timestamp (first record in file) and filling first column of csv with timestamp data based on it\n",
    "    year       = raw_data['DATE_YEAR']['data'][0][0][0,0]\n",
    "    month      = raw_data['DATE_MONTH']['data'][0][0][0,0]\n",
    "    day        = raw_data['DATE_DAY']['data'][0][0][0,0]\n",
    "    hour       = raw_data['GMT_HOUR']['data'][0][0][0,0]\n",
    "    minute     = raw_data['GMT_MINUTE']['data'][0][0][0,0]\n",
    "    sec        = raw_data['GMT_SEC']['data'][0][0][0,0]\n",
    "\n",
    "    # 687200403251247.mat\n",
    "    if month <1 or month > 12:\n",
    "      year = int(file_name[3:7])\n",
    "      month = int(file_name[7:9])\n",
    "      day = int(file_name[9:11])\n",
    "      hour = int(file_name[11:13])\n",
    "      minute = int(file_name[13:15])\n",
    "      sec = 0\n",
    "\n",
    "    base = datetime.datetime(year, month, day, hour, minute, sec)\n",
    "    date_list = [base + datetime.timedelta(seconds=x) for x in range(0, t_length)]\n",
    "    dates = np.array(date_list)\n",
    "#     flghtnum= np.repeat(file_name, len(dates))\n",
    "    # arr['timestamp'] = dates\n",
    "    feature_dict['timestamp'] =  feature_dict['timestamp'] + (dates.T).tolist()\n",
    "    \n",
    "    # Filling all feature vector columns in the recarray\n",
    "    for key in features_1:\n",
    "        data =  raw_data[key]['data'][0][0]\n",
    "        rate =  raw_data[key]['Rate'][0][0][0][0]\n",
    "        dtype = raw_data[key]['data'][0][0].dtype\n",
    "        # Add column to the recarray with proper dtype\n",
    "        # arr = recfn.rec_append_fields(arr, key, arrs_1d, dtype)\n",
    "        # Normalize vector to 1Hz by subsampling original vector\n",
    "        norm_v = data[0:data.size:rate]\n",
    "        # Add normalized feature data vector to added column\n",
    "        # arr[key] = norm_v.T\n",
    "        feature_dict[key] = feature_dict[key] + (norm_v.T).tolist()[0]\n",
    "    size_1hz = len(norm_v)\n",
    "    for key in features_25:\n",
    "        data =  raw_data[key]['data'][0][0]\n",
    "        rate =  raw_data[key]['Rate'][0][0][0][0]\n",
    "        dtype = raw_data[key]['data'][0][0].dtype\n",
    "        # Add column to the recarray with proper dtype\n",
    "        # arr = recfn.rec_append_fields(arr, key, arrs_1d, dtype)\n",
    "        # Normalize vector to 1Hz by subsampling original vector\n",
    "        norm_v = np.resize(data,(size_1hz,1))\n",
    "        # Add normalized feature data vector to added column\n",
    "        # arr[key] = norm_v.T\n",
    "        feature_dict[key] = feature_dict[key] + (norm_v.T).tolist()[0]\n",
    "        # print((norm_v.T).tolist()[0])\n",
    "    return\n",
    "\n",
    "def write_output(firstDataFrame,method):\n",
    "  if method == \"CSV\":\n",
    "    firstDataFrame.to_csv(\"Data_1.csv\")\n",
    "    print(\"Written Successfully\")\n",
    "  elif method == \"JSON\":\n",
    "    results = firstDataFrame.to_json('Data_1.json',orient=\"split\")\n",
    "    print(\"Written SucessFully !\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  start = datetime.datetime.now()\n",
    "  file_list = glob.glob('' + \"*.mat\")\n",
    "  feature_dict = {}\n",
    "  # print(file_list)\n",
    "  # file_list = ['687200403251247.mat', '687200403251438.mat', '687200403251602.mat', '687200403251723.mat', '687200403260749.mat',]\n",
    "  # file_list = ['687200403251247.mat']\n",
    "  for ind,fileName in enumerate(file_list):\n",
    "      file_name = fileName\n",
    "      raw_mat_data_dict = open_mat_file(file_name)\n",
    "      features_25, features_1, data_def = extract_features(raw_mat_data_dict)\n",
    "      if ind == 0:\n",
    "        feature_vector_array(raw_mat_data_dict, features_25, features_1,file_name)\n",
    "      else:\n",
    "        feature_dictionary(feature_dict,raw_mat_data_dict,features_25, features_1,file_name)\n",
    "      print(\"Processed {} file\".format(ind))\n",
    "  # result = pd.DataFrame.from_dict(feature_dict)\n",
    "      # if ind == 0:\n",
    "      #   # firstDataFrame = pd.DataFrame.from_records(feature_array)\n",
    "      #   firstDataFrame = pd.DataFrame.from_dict(feature_array)\n",
    "      # else:\n",
    "      #   # firstDataFrame = pd.concat([firstDataFrame,pd.DataFrame.from_records(feature_array)])\n",
    "      #   firstDataFrame = pd.concat([firstDataFrame,pd.DataFrame.from_dict(feature_array)])\n",
    "  \n",
    "  # firstDataFrame.reset_index(inplace = True)\n",
    "  # write_output(firstDataFrame,method = \"JSON\")\n",
    "  end = datetime.datetime.now()\n",
    "  print(\"Time Taken to run the funtion \",str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to run Flight 652 1 Flight 652/1/652200101092009.mat 0:00:00.117485\n",
      "Time Taken to run Flight 652 1 Flight 652/1/652200101092046.mat 0:00:00.094606\n",
      "Time Taken to run Flight 652 1 Flight 652/1/652200101100441.mat 0:00:00.084753\n",
      "Time Taken to run Flight 652 1 Flight 652/1/652200101111519.mat 0:00:00.103541\n",
      "Time Taken to run Flight 652 1 Flight 652/1/652200101111622.mat 0:00:00.289323\n",
      "Time Taken to run Flight 652 1 Flight 652/1/652200101112303.mat 0:00:00.185951\n",
      "Time Taken to run Flight 652 1 Flight 652/1/652200101120916.mat 0:00:00.150010\n",
      "Time Taken to run Flight 652 1 Flight 652/1/652200101121117.mat 0:00:00.096959\n",
      "Time Taken to run Flight 652 1 Flight 652/1/652200101121118.mat 0:00:00.192247\n",
      "Time Taken to run Flight 652 1 Flight 652/1/652200101121218.mat 0:00:00.180943\n",
      "Time Taken to run Flight 652 1 Flight 652/1/652200101121341.mat 0:00:00.206392\n"
     ]
    }
   ],
   "source": [
    "for ind, key in enumerate(key_list):\n",
    "    start = datetime.datetime.now()\n",
    "    s3_key = key.key\n",
    "    flght,set_num,date_s= s3_key.split('.')[0].split('/')\n",
    "    raw_mat = load_mat_file(s3_key)\n",
    "    features_25, features_1, data_def= extract_features(raw_mat)\n",
    "    feature_vector_array(raw_mat, features_25, features_1,date_s)\n",
    "    end = datetime.datetime.now()\n",
    "    print(\"Time Taken to run\",flght,set_num, s3_key, str(end-start))\n",
    "    del(raw_mat)\n",
    "    if ind ==100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LTj0dWOgJ3f"
   },
   "outputs": [],
   "source": [
    "#  Time Taken for open_mat_file Function = 00.21 min\n",
    "#  Time taken for extract Features = 00.01 min\n",
    "#  Time Taken for feature_vector_array = 9:00 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1O0b4JZdEvD"
   },
   "outputs": [],
   "source": [
    "time_str = []\n",
    "for v in feature_dict['timestamp']:\n",
    "  time_str.append(v.strftime(\"%d-%b-%Y (%H:%M:%S.%f)\"))\n",
    "\n",
    "feature_dict['timestamp'] = time_str\n",
    "\n",
    "with open('result.json', 'w') as fp:\n",
    "    json.dump(feature_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpZNy_Qyd0to"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qC9TA08DKFPP"
   },
   "outputs": [],
   "source": [
    "\n",
    "# len(firstDataFrame) is 1619916\n",
    "# len(feature_dict['FPAC']) is 1619916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "tYoPLv_TfbaO",
    "outputId": "c17e3f28-d4f1-4a9a-e8ec-949778a27605"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGMu-inBFm0a"
   },
   "outputs": [],
   "source": [
    "destination_df = firstDataFrame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "cir2EMVCFzYj",
    "outputId": "1e99c0c1-72a4-4ff5-d064-3cb7cbd16205"
   },
   "outputs": [],
   "source": [
    "destination_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "d5OVDXzzps7D",
    "outputId": "190079d2-261c-43e0-f32e-4db10b24c9d4"
   },
   "outputs": [],
   "source": [
    "#  Time Taken for open_mat_file Function = 00.21 min\n",
    "#  Time taken for extract Features = 00.01 min\n",
    "#  Time Taken for feature_vector_array = 26:00 min\n",
    "#  Time Taken for Writing = 8 min\n",
    "# Time Taken = 34 min\n",
    "raw_mat_data_dict['TRKM']['Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SmrrqLRmYIr"
   },
   "outputs": [],
   "source": [
    "firstDataFrame.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DYJB6kunm-RH"
   },
   "outputs": [],
   "source": [
    "results = firstDataFrame.to_json('tata.json',orient=\"split\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "mEkPj-EF7ntf",
    "outputId": "a0ad092a-d759-45fa-c3a2-d966bf50ad1f"
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "l =[1,2,3]\n",
    "g = [2,3,4]\n",
    "l+g\n",
    "end = datetime.datetime.now()\n",
    "print(\"Time Taken to run the funtion \",str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FbfXa9CmQkc3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Nasa_Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
